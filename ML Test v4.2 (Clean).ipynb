{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML Test v4.2 (Clean).ipynb","provenance":[],"authorship_tag":"ABX9TyNZsuyfIXyICZoMvM+Doqn9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-7cM45gCKWBG"},"source":["# Libraries Import"]},{"cell_type":"code","metadata":{"id":"rTVF4gc6JjJ7"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","!pip install mtcnn\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import numpy as np\n","import torch.utils.data as data_utils\n","import matplotlib.pyplot as plt\n","import os\n","\n","from keras.models import Model, Sequential, model_from_json\n","from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dropout, Activation\n","from keras.applications.vgg16 import preprocess_input\n","from keras.preprocessing import image\n","from matplotlib.patches import Rectangle \n","from mtcnn.mtcnn import MTCNN\n","from scipy import spatial, optimize, stats, ndimage, misc, \n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, TensorDataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZD9_gQb5KbIQ"},"source":["# Couple Images Pre-processing Architecture \n","## Extraction of couple faces ---> (Cosine Distance, Euclidean Distance, Pearson Correlation)"]},{"cell_type":"code","metadata":{"id":"ugQHdAeiKwUA"},"source":["model = Sequential()\n","model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n","model.add(Convolution2D(64, (3, 3), activation='relu'))\n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2,2), strides=(2,2)))\n"," \n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(128, (3, 3), activation='relu'))\n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(128, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2,2), strides=(2,2)))\n"," \n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(256, (3, 3), activation='relu'))\n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(256, (3, 3), activation='relu'))\n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(256, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2,2), strides=(2,2)))\n"," \n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(512, (3, 3), activation='relu'))\n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(512, (3, 3), activation='relu'))\n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(512, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2,2), strides=(2,2)))\n"," \n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(512, (3, 3), activation='relu'))\n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(512, (3, 3), activation='relu'))\n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(512, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2,2), strides=(2,2)))\n"," \n","model.add(Convolution2D(4096, (7, 7), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Convolution2D(4096, (1, 1), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Convolution2D(2622, (1, 1)))\n","model.add(Flatten())\n","model.add(Activation('softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uvgNi-yfK_iM"},"source":["model.load_weights('/content/gdrive/MyDrive/A - Academics UM/A - Machine Learning/Grp Project/Final Trial v1.0/vgg_face_weights.h5')\n","vgg_face_descriptor = Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AGsr1fkRMSMh"},"source":["### Methods to extract couple faces in image dataset"]},{"cell_type":"code","metadata":{"id":"KEHVFOz_LE-S"},"source":["def extract_face(filename, image_size=(224, 224)):\n","  image = cv2.imread(filename)\n","  image_data = np.asarray(image)\n","  detector = MTCNN()\n","  results = detector.detect_faces(image_data)\n","  x_0, y_0, width_0, height_0 = results[0]['box']\n","  x_0, y_0 = abs(x_0), abs(y_0)\n","  x_0_up, y_0_up = x_0 + width_0, y_0 + width_0\n","  face_0 = image_data[y_0:y_0_up, x_0:x_0_up]\n","  face_array_0 = cv2.resize(face_0,image_size,interpolation=cv2.INTER_CUBIC)\n","  face_array_0 = face_array_0.reshape(1, 224, 224, 3)\n","\n","  x_1, y_1, width_1, height_1 = results[1]['box']\n","  x_1, y_1 = abs(x_1), abs(y_1)\n","  x_1_up, y_1_up = x_1 + width_1, y_1 + width_1\n","  face_1 = image_data[y_1:y_1_up, x_1:x_1_up]\n","  face_array_1 = cv2.resize(face_1,image_size,interpolation=cv2.INTER_CUBIC)\n","  face_array_1 = face_array_1.reshape(1, 224, 224, 3)\n","  return face_array_0, face_array_1\n","\n","def get_embeddings(file):\n","  faces_0, faces_1 = extract_face(file)\n","  samples_0 = np.asarray(faces_0, 'float32')\n","  samples_0 = preprocess_input(samples_0)\n","  representation_0 = vgg_face_descriptor.predict(samples_0)\n","  samples_1 = np.asarray(faces_1, 'float32')\n","  samples_1 = preprocess_input(samples_1)\n","  representation_1 = vgg_face_descriptor.predict(samples_1)\n","  return representation_0, representation_1\n","\n","def draw_image_with_boxes(filename, result_list):\n","  data = plt.imread(filename)\n","  plt.imshow(data)\n","  ax = plt.gca()\n","  for result in result_list:\n","    x, y, width, height = result['box']\n","    rect = Rectangle((x, y), width, height, fill=False, color='red')\n","    ax.add_patch(rect)\n","  plt.show()\n","\n","def findFace(filename):\n","  pixels = plt.imread(filename)\n","  detector = MTCNN()\n","  faces = detector.detect_faces(pixels)\n","  draw_image_with_boxes(filename, faces)\n","\n","def twoFace(filename):\n","  image = cv2.imread(filename)\n","  image_data = np.asarray(image)\n","  detector = MTCNN()\n","  results = detector.detect_faces(image_data)\n","  return len(results)\n","\n","def calculateCompatibility(file):\n","  representation_0, representation_1 = get_embeddings(file)\n","  findFace(file)\n","  d = spatial.distance.cosine(representation_0, representation_1)\n","  print(\"Compatibility : {:.5f}%\".format(d * 100))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FfkFqG_JMK0Y"},"source":["### Methods to compute (Cosine Distance, Euclidean Distance, Pearson Correlation)"]},{"cell_type":"code","metadata":{"id":"wWd6EB77LTPE"},"source":["def distanceGenerator(file):\n","  representation_0, representation_1 = get_embeddings(file)\n","  #print((representation_0[0]))\n","  #print((representation_1[0]))\n","  dCosine = spatial.distance.cosine(representation_0, representation_1)\n","  dEuc = np.linalg.norm(representation_0 - representation_1)\n","  #print(type(representation_0))\n","  Pear = stats.pearsonr(representation_0[0], representation_1[0])\n","  #print(Pear)\n","  return dCosine, dEuc, Pear[0], Pear[1]\n","\n","def datasetFromImage(path, couple):\n","  dCosineArr = np.array([])\n","  dEucArr = np.array([])\n","  PearRArr = np.array([])\n","  PearPArr = np.array([])\n","  for image_path in os.listdir(path):\n","    input_path = os.path.join(path, image_path)\n","    if twoFace(input_path) == 2:\n","      dCosine, dEuc, PearR, PearP = distanceGenerator(input_path)\n","      dCosineArr = np.append(dCosineArr, dCosine)\n","      dEucArr = np.append(dEucArr, dEuc)\n","      PearRArr = np.append(PearRArr, PearR)\n","      PearPArr = np.append(PearPArr, PearP)\n","  if couple == True:\n","    LabelArr = np.ones(dCosineArr.shape)\n","  else:\n","    LabelArr = np.zeros(dCosineArr.shape)\n","  return dCosineArr, dEucArr, PearRArr, PearPArr, LabelArr\n","\n","def dataset(couplePath, notCouplePath):\n","  dCosineArrC, dEucArrC, PearRArrC, PearPArrC, LabelArrC = datasetFromImage(couplePath, True)\n","  dCosineArrNC, dEucArrNC, PearRArrNC, PearPArrNC, LabelArrNC = datasetFromImage(notCouplePath, False)\n","  dCosineArr = np.concatenate([dCosineArrC,dCosineArrNC])\n","  dEucArr = np.concatenate([dEucArrC,dEucArrNC])\n","  PearRArr = np.concatenate([PearRArrC,PearRArrNC])\n","  PearPArr = np.concatenate([PearPArrC,PearPArrNC])\n","  LabelArr = np.concatenate([LabelArrC,LabelArrNC])\n","  dataset = pd.DataFrame({'Cosine': dCosineArr, 'Euclidean': dEucArr, 'PearsonR': PearRArr, 'PearsonP': PearPArr, \n","                          'Label': LabelArr}, columns=['Cosine', 'Euclidean', 'PearsonR', 'PearsonP', 'Label'])\n","  return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"te6ZuCF1KnXh"},"source":["# Couple Compatibility Model"]},{"cell_type":"code","metadata":{"id":"k5ZFGg6oM375"},"source":["seed = 98\n","torch.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(seed)\n","\n","trainDf = pd.read_csv('/content/gdrive/MyDrive/Final Trial v1.0/dataset.csv')\n","trainLabel = trainDf.pop('Label')\n","train_tensor = data_utils.TensorDataset(torch.tensor(trainDf.values.astype(np.float64)), torch.tensor(trainLabel.values.astype(np.float64)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_2ZbBjf5KhIl"},"source":[""],"execution_count":null,"outputs":[]}]}